{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vivek/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from voc import parse_voc_annotation\n",
    "from yolo import create_yolov3_model, dummy_loss\n",
    "from generator import BatchGenerator\n",
    "from utils.utils import normalize, evaluate, makedirs\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from callbacks import CustomModelCheckpoint, CustomTensorBoard\n",
    "from utils.multi_gpu_model import multi_gpu_model\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_input_size =    288\n",
    "max_input_size=448\n",
    "anchors =              [55,69, 75,234, 133,240, 136,129, 142,363, 203,290, 228,184, 285,359, 341,260]\n",
    "labels=['reccoon']\n",
    "train_times=          8\n",
    "batch_size=   16\n",
    "learning_rate=      1e-4\n",
    "nb_epochs=            100\n",
    "warmup_epochs=       3\n",
    "ignore_thresh=  0.5\n",
    "gpus=   0,1\n",
    "grid_scales =       [1,1,1]\n",
    "obj_scale=            5\n",
    "noobj_scale=          1\n",
    "xywh_scale=          1\n",
    "class_scale =        1\n",
    "saved_weights_name='reccoon.weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto(\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_training_instances(\n",
    "    train_annot_folder,\n",
    "    train_image_folder,\n",
    "    train_cache,\n",
    "    valid_annot_folder,\n",
    "    valid_image_folder,valid_cache,labels\n",
    "):\n",
    "        train_ints,train_labels = parse_voc_annotation(train_annot_folder, train_image_folder,train_cache,labels)\n",
    "        print(train_labels)\n",
    "    # parse annotations of the validation set, if any, otherwise split the training set\n",
    "        valid_ints, valid_labels = parse_voc_annotation(valid_annot_folder,valid_image_folder,valid_cache,labels)\n",
    "        \n",
    "        if len(labels) > 0:\n",
    "                overlap_labels = set(labels).intersection(set(train_labels.keys()))\n",
    "\n",
    "                print('Seen labels: \\t'  + str(train_labels) + '\\n')\n",
    "                print('Given labels: \\t' + str(labels))\n",
    "\n",
    "        # return None, None, None if some given label is not in the dataset\n",
    "                if len(overlap_labels) < len(labels):\n",
    "                     print('Some labels have no annotations! Please revise the list of labels in the config.json.')\n",
    "                     return None, None, None\n",
    "        else:\n",
    "             print('No labels are provided. Train on all seen labels.')\n",
    "             print(train_labels)\n",
    "             labels = train_labels.keys()\n",
    "        \n",
    "        max_box_per_image=max([len(inst['object']) for inst in (train_ints + valid_ints)])\n",
    "        return train_ints, valid_ints, sorted(labels),max_box_per_image   \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n   checkpoint = ModelCheckpoint(\\n        \\n        filepath        = 'reccoon.h5',# + '{epoch:02d}.h5', \\n        monitor         = 'loss', \\n        verbose         = 1, \\n        save_best_only  = True, \\n        mode            = 'min', \\n        period          = 1\\n    )\\n    reduce_on_plateau = ReduceLROnPlateau(\\n        monitor  = 'loss',\\n        factor   = 0.1,\\n        patience = 2,\\n        verbose  = 1,\\n        mode     = 'min',\\n        epsilon  = 0.01,\\n        cooldown = 0,\\n        min_lr   = 0)  \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_callbacks(saved_weights_name, tensorboard_logs, model_to_save):\n",
    "    makedirs(tensorboard_logs)\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor     = 'loss', \n",
    "        min_delta   = 0.01, \n",
    "        patience    = 7, \n",
    "        mode        = 'min', \n",
    "        verbose     = 1\n",
    "    )\n",
    "   \n",
    "    return [early_stop]\n",
    "\n",
    "\n",
    "'''\n",
    "   checkpoint = ModelCheckpoint(\n",
    "        \n",
    "        filepath        = 'reccoon.h5',# + '{epoch:02d}.h5', \n",
    "        monitor         = 'loss', \n",
    "        verbose         = 1, \n",
    "        save_best_only  = True, \n",
    "        mode            = 'min', \n",
    "        period          = 1\n",
    "    )\n",
    "    reduce_on_plateau = ReduceLROnPlateau(\n",
    "        monitor  = 'loss',\n",
    "        factor   = 0.1,\n",
    "        patience = 2,\n",
    "        verbose  = 1,\n",
    "        mode     = 'min',\n",
    "        epsilon  = 0.01,\n",
    "        cooldown = 0,\n",
    "        min_lr   = 0)  \n",
    "'''\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    nb_class, \n",
    "    anchors, \n",
    "    max_box_per_image, \n",
    "    max_grid, batch_size, \n",
    "    warmup_batches, \n",
    "    ignore_thresh, \n",
    "  \n",
    "    saved_weights_name, \n",
    "    lr,\n",
    "    grid_scales,\n",
    "    obj_scale,\n",
    "    noobj_scale,\n",
    "    xywh_scale,\n",
    "    class_scale  \n",
    "):\n",
    "     template_model, infer_model = create_yolov3_model(\n",
    "            nb_class            = nb_class, \n",
    "            anchors             = anchors, \n",
    "            max_box_per_image   = max_box_per_image, \n",
    "            max_grid            = max_grid, \n",
    "            batch_size          = batch_size, \n",
    "            warmup_batches      = warmup_batches,\n",
    "            ignore_thresh       = ignore_thresh,\n",
    "            grid_scales         = grid_scales,\n",
    "            obj_scale           = obj_scale,\n",
    "            noobj_scale         = noobj_scale,\n",
    "            xywh_scale          = xywh_scale,\n",
    "            class_scale         = class_scale\n",
    "        )  \n",
    "#loading_weight\n",
    "     if os.path.exists(saved_weights_name): \n",
    "        print(\"\\nLoading pretrained weights.\\n\")\n",
    "        template_model.load_weights(saved_weights_name)\n",
    "     else :\n",
    "        template_model.load_weights(\"backend.h5\", by_name=True)\n",
    "     optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "     train_model = template_model   \n",
    "     train_model.compile(loss=dummy_loss, optimizer=optimizer)             \n",
    "\n",
    "     return train_model, infer_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raccoon': 163}\n",
      "Seen labels: \t{'raccoon': 163}\n",
      "\n",
      "Given labels: \t['raccoon']\n"
     ]
    }
   ],
   "source": [
    "train_ints, valid_ints,labels, max_box_per_image = create_training_instances(\n",
    "        '/home/vivek/machinevision/keras-yolo3-master/dataset/train_annot_folder/',\n",
    "        '/home/vivek/machinevision/keras-yolo3-master/dataset/train_image_folder/',\n",
    "        'reccoon_train.pkl',\n",
    "        '/home/vivek/machinevision/keras-yolo3-master/dataset/val_annot_folder/',\n",
    "        '/home/vivek/machinevision/keras-yolo3-master/dataset/val_image_folder/',\n",
    "    'reccoon_val.pkl', ['raccoon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on: \t['raccoon']\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print('\\nTraining on: \\t' + str(labels) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = BatchGenerator(\n",
    "        instances           = train_ints, \n",
    "        anchors             = anchors,   \n",
    "        labels              = labels,        \n",
    "        downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "        max_box_per_image   = max_box_per_image,\n",
    "        batch_size          = batch_size,\n",
    "        min_net_size        = min_input_size,\n",
    "        max_net_size        = max_input_size ,  \n",
    "        shuffle             = True, \n",
    "        jitter              = 0.3, \n",
    "        norm                = normalize)\n",
    "    \n",
    "valid_generator = BatchGenerator(\n",
    "        instances           = valid_ints, \n",
    "        anchors             = anchors,   \n",
    "        labels              = labels,        \n",
    "        downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "        max_box_per_image   = max_box_per_image,\n",
    "        batch_size          = batch_size,\n",
    "        min_net_size        =min_input_size,\n",
    "        max_net_size        = max_input_size ,  \n",
    "        shuffle             = True, \n",
    "        jitter              = 0.0, \n",
    "        norm                = normalize )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "warmup_batches = warmup_epochs *train_times*len(train_generator)\n",
    "print(warmup_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vivek/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/vivek/machinevision/keras-yolo3-master/yolo.py:30: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "train_model, infer_model = create_model(\n",
    "        nb_class            = len(labels), \n",
    "        anchors             = anchors, \n",
    "        max_box_per_image   = max_box_per_image, \n",
    "        max_grid            = [max_input_size,max_input_size], \n",
    "        batch_size          = batch_size, \n",
    "        warmup_batches      = warmup_batches,\n",
    "        ignore_thresh       = ignore_thresh,\n",
    "       \n",
    "        saved_weights_name  = saved_weights_name,\n",
    "        lr                  = learning_rate,\n",
    "        grid_scales         = grid_scales,\n",
    "        obj_scale           = obj_scale,\n",
    "        noobj_scale         = noobj_scale,\n",
    "        xywh_scale          = xywh_scale,\n",
    "        class_scale         = class_scale\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_callbacks('backend.h5','logs', infer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_model.fit_generator(\n",
    "        generator        = train_generator, \n",
    "        steps_per_epoch  = len(train_generator) * train_times, \n",
    "        epochs           =   2,    #nb_epochs+ warmup_epochs, \n",
    "        verbose          = 2 , \n",
    "        workers          = 4,\n",
    "        max_queue_size   = 8,\n",
    "     callbacks=callbacks\n",
    "     \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "infer_model = load_model('raccoon.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precisions = evaluate(infer_model, valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raccoon: 0.0003\n",
      "mAP: 0.0003\n"
     ]
    }
   ],
   "source": [
    "for label, average_precision in average_precisions.items():\n",
    "        print(labels[label] + ': {:.4f}'.format(average_precision))\n",
    "print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import cv2\n",
    "from utils.utils import get_yolo_boxes, makedirs\n",
    "from utils.bbox import draw_boxes\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('asd.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  8,  23,   9],\n",
       "        [  2,  17,   3],\n",
       "        [ 10,  26,   9],\n",
       "        ...,\n",
       "        [  0, 113,  44],\n",
       "        [  2, 107,  44],\n",
       "        [  3, 104,  42]],\n",
       "\n",
       "       [[  3,  18,   4],\n",
       "        [  4,  19,   5],\n",
       "        [  6,  22,   5],\n",
       "        ...,\n",
       "        [  0, 116,  47],\n",
       "        [  7, 113,  47],\n",
       "        [  5, 109,  44]],\n",
       "\n",
       "       [[  2,  15,   1],\n",
       "        [  2,  15,   1],\n",
       "        [  8,  23,   9],\n",
       "        ...,\n",
       "        [  1, 114,  46],\n",
       "        [  6, 115,  47],\n",
       "        [  8, 114,  47]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[106, 115, 129],\n",
       "        [107, 116, 129],\n",
       "        [107, 115, 128],\n",
       "        ...,\n",
       "        [  7,   6,  10],\n",
       "        [  1,   0,   2],\n",
       "        [  0,   0,   1]],\n",
       "\n",
       "       [[106, 115, 128],\n",
       "        [110, 120, 130],\n",
       "        [108, 118, 128],\n",
       "        ...,\n",
       "        [  6,   5,   9],\n",
       "        [  2,   1,   3],\n",
       "        [  2,   1,   3]],\n",
       "\n",
       "       [[111, 121, 131],\n",
       "        [116, 126, 136],\n",
       "        [113, 123, 133],\n",
       "        ...,\n",
       "        [  3,   2,   6],\n",
       "        [  0,   0,   1],\n",
       "        [  0,   0,   1]]], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_h, net_w = 416, 416 # a multiple of 32, the smaller the faster\n",
    "obj_thresh, nms_thresh = .52, .45\n",
    "# predict the bounding boxes\n",
    "boxes = get_yolo_boxes(infer_model, [image], net_h, net_w,[17,18, 28,24, 36,34, 42,44, 56,51, 72,66, 90,95, 92,154, 139,281], obj_thresh, nms_thresh)[0]\n",
    "\n",
    "# draw bounding boxes on the image using labels\n",
    "draw_boxes(image, boxes,labels, obj_thresh)\n",
    "#[55,69, 75,234, 133,240, 136,129, 142,363, 203,290, 228,184, 285,359, 341,260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('dfd5.jpeg', np.uint8(image))   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
